---
layout: page
title: Streaming
tagline: Hands-on session with Spark Streaming
description: Use the Spark Streaming API to perform real time data analysis.
---

For this assignment, you will take a look at how to analyze a continuous stream of data using Spark's own streaming API and write a blog post about working with it.

### Getting started
Run the `rubigdata/hadoop` docker container and open a shell in the container. Then:
```
cd /opt/docker/notebooks
wget https://gist.githubusercontent.com/WKuipers/aeaef868f4a02eef25d2dc1d56469bd0/raw/48eb32eec993bbe9475a2e8b97eee2701214e482/4%2520-%2520Streaming%2520Big%2520Data.snb
```
Now you should find the 4 - Streaming Big Data notebook in your spark notebook interface.

Assignment 4 consists of a notebook with some example code and pointers to get you started.

### Blog Post

Once again we would like you to write a blogpost on how you worked on the notebook and what the end result was.
Make sure you talk about at least
* What you found easy or difficult about the assignment/the Spark Streaming API
* The questions found in the notebook
* The code you wrote to do some analysis task at the end of the notebook and a brief explanation

Your blog post should posted on your main blog, as before. There is no seperate assignment repository for this assignment.

Happy Hacking!
[Back to assignments overview](../index.html)
